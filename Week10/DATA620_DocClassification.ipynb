{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used here is from [Apache SpamAssassin](data sourcehttps://spamassassin.apache.org/old/publiccorpus/) and contains a few thousand classified \"spam\" and \"ham\" emails.\n",
    "\n",
    "The uncompressed data is a bit large for github, so we've preprocessed the data and stored it in a single CSV file [here](https://raw.githubusercontent.com/plb2018/data620/master/Week10/spam_n_ham.csv) to make life easier.  The compressed data has been archived [here](https://github.com/plb2018/data620/tree/master/Week10/raw_data) for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "#here we preprocess the data - commented out to save on run-time.\n",
    "\n",
    "PATH = \"C:/Users/Paul/OneDrive - CUNY School of Professional Studies/CUNY/DATA 620/Week10/\"\n",
    "spam_folders = ['easy_ham/','spam/','easy_ham_2/','hard_ham/','spam_2/']\n",
    "\n",
    "cols = ['body','source','isSpam']\n",
    "df = pd.DataFrame(columns = cols)\n",
    "\n",
    "for folder in spam_folders:\n",
    "    files = [f for f in listdir(PATH+folder) if isfile(join(PATH+folder, f))]\n",
    "    \n",
    "    for f in files:\n",
    "        data = open(PATH+folder+f,'rb')\n",
    "          \n",
    "        newData = {'body':data.read(),\n",
    "                  'source':folder,\n",
    "                  'isSpam':0}\n",
    "        \n",
    "        df = df.append(newData,ignore_index=True)\n",
    "        data.close()\n",
    "\n",
    "#encode the spam as spam\n",
    "df['isSpam'][(df['source'] == 'spam/') | (df['source'] == 'spam_2/')] = 1   \n",
    "\n",
    "#df.to_csv(\"spam_n_ham.csv\",sep='|')\n",
    "\n",
    "'''\n",
    "\n",
    "#load the preprocessed data from github\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/plb2018/data620/master/Week10/spam_n_ham.csv',sep='|',index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9348, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " def cleanData(data):\n",
    "    data=str(data)\n",
    "    data = data.lower()\n",
    "    data=data.replace('{html}',\"\") \n",
    "    clnr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(clnr, '', data)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body']=df['body'].map(lambda s:cleanData(s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>source</th>\n",
       "      <th>isSpam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>exmh workers admin redhat com thu aug nreturn ...</td>\n",
       "      <td>easy_ham/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>steve_burt cursor system com thu aug nreturn p...</td>\n",
       "      <td>easy_ham/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>timc ubh com thu aug nreturn path ndelivered z...</td>\n",
       "      <td>easy_ham/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>irregulars admin thu aug nreturn path ndeliver...</td>\n",
       "      <td>easy_ham/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stewart smith thu aug nreturn path ndelivered ...</td>\n",
       "      <td>easy_ham/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>martin srv ems thu aug nreturn path ndelivered...</td>\n",
       "      <td>easy_ham/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>martin srv ems thu aug nreturn path ndelivered...</td>\n",
       "      <td>easy_ham/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stewart smith thu aug nreturn path ndelivered ...</td>\n",
       "      <td>easy_ham/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>martin srv ems thu aug nreturn path ndelivered...</td>\n",
       "      <td>easy_ham/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>exmh workers admin redhat com thu aug nreturn ...</td>\n",
       "      <td>easy_ham/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>spamassassin talk admin lists sourceforge net ...</td>\n",
       "      <td>easy_ham/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spamassassin devel admin lists sourceforge net...</td>\n",
       "      <td>easy_ham/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spamassassin devel admin lists sourceforge net...</td>\n",
       "      <td>easy_ham/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ilug admin linux thu aug nreturn path ndeliver...</td>\n",
       "      <td>easy_ham/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>exmh workers admin redhat com thu aug nreturn ...</td>\n",
       "      <td>easy_ham/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fork admin xent com thu aug nreturn path ndeli...</td>\n",
       "      <td>easy_ham/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>iiu admin taint org thu aug nreturn path ndeli...</td>\n",
       "      <td>easy_ham/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>robert chambers baesystems com thu aug nreturn...</td>\n",
       "      <td>easy_ham/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ilug admin linux thu aug nreturn path ndeliver...</td>\n",
       "      <td>easy_ham/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>robert chambers baesystems com thu aug nreturn...</td>\n",
       "      <td>easy_ham/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 body     source  isSpam\n",
       "0   exmh workers admin redhat com thu aug nreturn ...  easy_ham/       0\n",
       "1   steve_burt cursor system com thu aug nreturn p...  easy_ham/       0\n",
       "2   timc ubh com thu aug nreturn path ndelivered z...  easy_ham/       0\n",
       "3   irregulars admin thu aug nreturn path ndeliver...  easy_ham/       0\n",
       "4   stewart smith thu aug nreturn path ndelivered ...  easy_ham/       0\n",
       "5   martin srv ems thu aug nreturn path ndelivered...  easy_ham/       0\n",
       "6   martin srv ems thu aug nreturn path ndelivered...  easy_ham/       0\n",
       "7   stewart smith thu aug nreturn path ndelivered ...  easy_ham/       0\n",
       "8   martin srv ems thu aug nreturn path ndelivered...  easy_ham/       0\n",
       "9   exmh workers admin redhat com thu aug nreturn ...  easy_ham/       0\n",
       "10  spamassassin talk admin lists sourceforge net ...  easy_ham/       0\n",
       "11  spamassassin devel admin lists sourceforge net...  easy_ham/       0\n",
       "12  spamassassin devel admin lists sourceforge net...  easy_ham/       0\n",
       "13  ilug admin linux thu aug nreturn path ndeliver...  easy_ham/       0\n",
       "14  exmh workers admin redhat com thu aug nreturn ...  easy_ham/       0\n",
       "15  fork admin xent com thu aug nreturn path ndeli...  easy_ham/       0\n",
       "16  iiu admin taint org thu aug nreturn path ndeli...  easy_ham/       0\n",
       "17  robert chambers baesystems com thu aug nreturn...  easy_ham/       0\n",
       "18  ilug admin linux thu aug nreturn path ndeliver...  easy_ham/       0\n",
       "19  robert chambers baesystems com thu aug nreturn...  easy_ham/       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy: 0.8538150701212265\n"
     ]
    }
   ],
   "source": [
    "c = CountVectorizer(lowercase=True,\n",
    "                        stop_words='english',\n",
    "                        ngram_range = (1,1))\n",
    "\n",
    "counts = c.fit_transform(df['body'])\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(counts,df['isSpam'],test_size=0.9,random_state=42)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "predicted= clf.predict(X_test)\n",
    "\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(counts,df['isSpam'],test_size=0.9,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy: 0.8538150701212265\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "predicted= clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy: 0.8684491978609625\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf=TfidfVectorizer()\n",
    "\n",
    "text_tf= tf.fit_transform(df['body'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_tf, df['isSpam'], test_size=0.3, random_state=123)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "predicted= clf.predict(X_test)\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
